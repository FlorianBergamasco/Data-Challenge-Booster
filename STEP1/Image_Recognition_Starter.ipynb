{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Welcome to a tutorial to get you quickly up to speed with *deep learning*; from first principles, all the way to discussions of some of the intricate details. By the end of this part of the tutorial, you should be capable of understanding and producing a simple CNN (with a structure similar to LeNet architecture) in Keras, achieving a respectable level of accuracy on the first step of this challenge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convolutions\n",
    "\n",
    "It turns out that there is a very efficient way of pulling this off, and it makes advantage of the structure of the information encoded within an image---it is assumed that pixels that are spatially *closer* together will \"cooperate\" on forming a particular feature of interest much more than ones on opposite corners of the image. Also, if a particular (smaller) feature is found to be of great importance when defining an image's label, it will be equally important if this feature was found anywhere within the image, regardless of location.\n",
    "\n",
    "Enter the **convolution** operator. Given a two-dimensional image, $\\bf I$, and a small matrix, $\\bf K$ of size $h \\times w$, (known as a *convolution kernel*), which we assume encodes a way of extracting an interesting image feature, we compute the convolved image, ${\\bf I} * {\\bf K}$, by overlaying the kernel on top of the image in all possible ways, and recording the sum of elementwise products between the image and the kernel:\n",
    "\n",
    "$$({\\bf I} * {\\bf K})_{xy} = \\sum_{i=1}^h \\sum_{j=1}^w {{\\bf K}_{ij} \\cdot {\\bf I}_{x + i - 1, y + j - 1}}$$\n",
    "\n",
    "(in fact, the exact definition would require us to flip the kernel matrix first, but for the purposes of machine learning it is irrelevant whether this is done)\n",
    "\n",
    "The images below show a diagrammatical overview of the above formula and the result of applying convolution (with two separate kernels) over an image, to act as an edge detector:\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/convolve.png)\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/lena.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convolutional layers and Pooling layers\n",
    "\n",
    "The convolution operator forms the fundamental basis of the **convolutional** layer of a CNN. The layer is completely specified by a certain number of kernels, $\\bf \\vec{K}$ (along with additive biases, $\\vec{b}$, per each kernel), and it operates by computing the convolution of the output images of a previous layer with each of those kernels, afterwards adding the biases (one per each output image). Finally, an activation function, $\\sigma$, may be applied to all of the pixels of the output images. Typically, the input to a convolutional layer will have $d$ *channels* (e.g. red/green/blue in the input layer), in which case the kernels are extended to have this number of channels as well, making the final formula of a single output image channel of a convolutional layer (for a kernel ${\\bf K}$ and bias $b$) as follows:\n",
    "\n",
    "$$\\mathrm{conv}({\\bf I}, {\\bf K})_{xy} = \\sigma\\left(b + \\sum_{i=1}^h \\sum_{j=1}^w \\sum_{k=1}^d {{\\bf K}_{ijk} \\cdot {\\bf I}_{x + i - 1, y + j - 1, k}}\\right)$$\n",
    "\n",
    "Note that, since all we're doing here is addition and scaling of the input pixels, the kernels may be learned from a given training dataset via *gradient descent*, exactly as the weights of an MLP. In fact, an MLP is perfectly capable of replicating a convolutional layer, but it would require a lot more training time (and data) to learn to approximate that mode of operation.\n",
    "\n",
    "Finally, let's just note that a convolutional operator is in no way restricted to two-dimensionally structured data: in fact, most machine learning frameworks ([Keras included](https://keras.io/layers/convolutional/)) will provide you with out-of-the-box layers for 1D and 3D convolutions as well!\n",
    "\n",
    "It is important to note that, while a convolutional layer significantly decreases the number of *parameters* compared to a fully connected (FC) layer, it introduces more **hyperparameters**---parameters whose values need to be chosen *before* training starts.\n",
    "\n",
    "Namely, the hyperparameters to choose within a single convolutional layer are:\n",
    "- *depth*: how many different kernels (and biases) will be convolved with the output of the previous layer;\n",
    "- *height* and *width* of each kernel;\n",
    "- *stride*: by how much we shift the kernel in each step to compute the next pixel in the result. This specifies the overlap between individual output pixels, and typically it is set to $1$, corresponding to the formula given before. Note that larger strides result in smaller output sizes.\n",
    "- *padding*: note that convolution by any kernel larger than $1\\times 1$ will *decrease* the output image size---it is often desirable to keep sizes the same, in which case the image is sufficiently padded with zeroes at the edges. This is often called *\"same\"* padding, as opposed to *\"valid\"* (no) padding. It is possible to add arbitrary levels of padding, but typically the padding of choice will be either same or valid.\n",
    "\n",
    "As already hinted, convolutions are not typically meant to be the sole operation in a CNN (although there have been promising recent developments on [all-convolutional networks](https://arxiv.org/pdf/1412.6806v3.pdf)); but rather to extract useful features of an image prior to downsampling it sufficiently to be manageable by an MLP.\n",
    "\n",
    "A very popular approach to downsampling is a *pooling* layer, which consumes small and (usually) disjoint chunks of the image (typically $2\\times 2$) and aggregates them into a single value. There are several possible schemes for the aggregation---the most popular being **max-pooling**, where the maximum pixel value within each chunk is taken. A diagrammatical illustration of $2\\times 2$ max-pooling is given below.\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/pool.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convolutional Neural Network (CNN) architecture\n",
    "\n",
    "Now that we got all the building blocks, let's see what a typical convolutional neural network might look like!\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/cnn.png)\n",
    "\n",
    "A typical CNN architecture for a $k$-class image classification can be split into two distinct parts---a chain of repeating $\\mathrm{Conv}\\rightarrow\\mathrm{Pool}$ layers (sometimes with more than one convolutional layer at once), followed by a few fully connected layers (taking each pixel of the computed images as an independent input), culminating in a $k$-way softmax layer, to which a cross-entropy loss is optimised. I did not draw the activation functions here to make the sketch clearer, but do keep in mind that typically after every convolutional or fully connected layer, an activation (e.g. ReLU) will be applied to all of the outputs.\n",
    "\n",
    "Note the effect of a single $\\mathrm{Conv}\\rightarrow\\mathrm{Pool}$ pass through the image: it reduces height and width of the individual channels in favour of their number, i.e. *depth*.\n",
    "\n",
    "For summarisation purposes, a softmax layer's purpose is converting any vector of real numbers into a vector of *probabilities* (nonnegative real values that add up to 1). Within this context, the probabilities correspond to the likelihoods that an input image is a member of a particular class. Minimising the cross-entropy loss has the effect of maximising the model's confidence in the *correct* class, without being concerned for the probabilites for other classes---this makes it a more suitable choice for probabilistic tasks compared to, for example, the squared error loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detour: Overfitting, regularisation and dropout\n",
    "\n",
    "It regards a very important pitfall of machine learning---**overfitting** a model to the training data and we need to introduce a way to properly protect ourselves against it, before going any further. Luckily, there is a very simple technique we can use.\n",
    "\n",
    "Overfitting corresponds to adapting our model to the training set to such extremes that its generalisation potential (performance on samples outside of the training set) is *severely* limited. In other words, our model might have learned the training set (along with any noise present within it) perfectly, but it has failed to capture the underlying process that generated it. To illustrate, consider a problem of fitting a sine curve, with white additive noise applied to the data points: \n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/plotsin.png)\n",
    "\n",
    "Here we have a training set (denoted by blue circles) derived from the original sine wave, along with some noise. If we fit a degree-3 polynomial to this data, we get a fairly good approximation to the original curve. Someone might argue that a degree-14 polynomial would do better; indeed, given we have 15 points, such a fit would *perfectly* describe the training data. However, in this case, the additional parameters of the model cause catastrophic results: to cope with the inherent noise of the data, anywhere except in the closest vicinity of the training points, our fit is completely off.\n",
    "\n",
    "Deep convolutional neural networks have a large number of parameters, especially in the fully connected layers. Overfitting might often manifest in the following form: if we don't have sufficiently many training examples, a small group of neurons might become responsible for doing most of the processing and other neurons becoming redundant; or in the other extreme, some neurons might actually become detrimental to performance, with several other neurons of their layer ending up doing nothing else but correcting for their errors.\n",
    "\n",
    "To help our models generalise better in these circumstances, we introduce techniques of *regularisation*: rather than reducing the number of parameters, we impose *constraints* on the model parameters during training to keep them from learning the noise in the training data. The particular method introduced here is **dropout**---a technique that initially might seem like \"dark magic\", but actually helps to eliminate exactly the failure modes described above. Namely, dropout with parameter $p$ will, within a single training iteration, go through all neurons in a particular layer and, with probability $p$, *completely eliminate them from the network throughout the iteration*. This has the effect of forcing the neural network to cope with *failures*, and not to rely on existence of a particular neuron (or set of neurons)---relying more on a *consensus* of several neurons within a layer. This is a very simple technique that works quite well already for combatting overfitting on its own, without introducing further regularisers. An illustration is given below.\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/drop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applying a deep CNN to Challenge Data Set\n",
    "\n",
    "As this post's objective, we will implement a deep convolutional neural network---and apply it on our satellites images data set in order to classify those : parking/not parking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, a CNN will typically have more hyperparameters than an MLP. For the purposes of this tutorial, we will also stick to \"sensible\" hand-picked values for them.\n",
    "\n",
    "The hyperparameters are:\n",
    "- The *batch size*, representing the number of training examples being used simultaneously during a single iteration of the gradient descent algorithm;\n",
    "- The number of *epochs*, representing the number of times the training algorithm will iterate over the entire training set before terminating\\*;\n",
    "- The *kernel sizes* in the convolutional layers;\n",
    "- The *pooling size* in the pooling layers;\n",
    "- The *number of kernels* in the convolutional layers;\n",
    "- The *dropout probability* (we will apply dropout after each pooling, and after the fully connected layer);\n",
    "- The *number of neurons* in the fully connected layer of the MLP.\n",
    "\n",
    "\\* **N.B. here I have set the number of epochs to 100, which might be undesirably slow if you do not have a GPU at your disposal (the convolution layers are going to pose a significant performance bottleneck in this case). You might wish to decrease the epoch count and/or numbers of kernels if you are going to be training the network on a CPU.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling time! Our network has an architecture similar to LeNet5 of LeCun (see figure below). It will consist of two consecutive groups of one `Convolution2D` followed by  a `MaxPooling2D` layer. After the first pooling layer, the number of kernels is rougly doubled (in line with the previously mentioned principle of sacrificing height and width for more depth). Afterwards, the output of the second pooling layer is flattened to 1D (via the `Flatten` layer), and passed through one or two fully connected (`Dense`) layers. ReLU activations will once again be used for all layers except the output dense layer, which will use a softmax activation (for purposes of probabilistic classification).\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/lenet5.png)\n",
    "\n",
    "To regularise our model, a `Dropout` layer is applied after each pooling layer, and after the first `Dense` layer. This is another area where Keras shines compared to other frameworks: it has an internal flag that automatically enables or disables dropout, depending on whether the model is currently used for training or testing.\n",
    "\n",
    "The remainder of the model specification is the following:\n",
    "- We use the *cross-entropy* loss function as the objective to optimise (as its derivation is more appropriate for probabilistic tasks);\n",
    "- We use the [*Adam* optimiser for gradient descent](http://sebastianruder.com/optimizing-gradient-descent/);\n",
    "- We report the *accuracy* of the model (as the dataset is balanced across the ten classes)\\*;\n",
    "- We hold out 10% of the data for validation purposes.\n",
    "\n",
    "\\* To get a feeling for why accuracy might be inappropriate for unbalanced datasets, consider an extreme case where 90% of the test data belongs to class $x$ (this could be, for example, the task of diagnosing patients for an extremely rare disease). In this case, a classifier that just outputs $x$ achieves a seemingly impressive accuracy of 90% on the test data, without really doing any learning/generalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Just show me the code!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code assume your already have installed <code>numpy</code>, <code>keras</code>, <code>tensorflow</code>, ... on your computer. If not, uncomment the adequate lines in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your python version: 3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Your python version: {}'.format(sys.version_info.major))\n",
    "# Uncomment lines below only if you need them \n",
    "#!{sys.executable} -m pip install -U numpy --user\n",
    "#!{sys.executable} -m pip install -U matplotlib --user\n",
    "#!{sys.executable} -m pipinstall -U keras --user\n",
    "#!{sys.executable} -m pip install -U tensorflow --user\n",
    "#!{sys.executable} -m pip install -U theano --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USE_TENSORFLOW_AS_BACKEND' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e547fe1d049e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mUSE_TENSORFLOW_AS_BACKEND\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'KERAS_BACKEND'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'KERAS_BACKEND'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'theano'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mFORCE_CPU\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'USE_TENSORFLOW_AS_BACKEND' is not defined"
     ]
    }
   ],
   "source": [
    "if USE_TENSORFLOW_AS_BACKEND:\n",
    "    os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "else:\n",
    "    os.environ['KERAS_BACKEND'] = 'theano'\n",
    "if FORCE_CPU:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your keras version: 2.2.4\n",
      "Your tensorflow version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "from keras.preprocessing import image\n",
    "print('Your keras version: {}'.format(keras.__version__))\n",
    "import tensorflow\n",
    "print('Your tensorflow version: {}'.format(tensorflow.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-5e4d9fc6ba5c>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-5e4d9fc6ba5c>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    pathtrain.append(row[0])\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Dataset variables\n",
    "\n",
    "height, width, depth = 256, 256, 3 # Our Images are 256*256 pixels, and coloured so 3 channels ( bleu/green/red)\n",
    "num_classes = 2 \n",
    "set_test_size=2000\n",
    "pathtrain=[]\n",
    "Y_train=[]\n",
    "pathholdout=[]\n",
    "# there are 2 classes parking/notparking\n",
    "# --------------------------------------\n",
    "# Dataset loading & preprocessing\n",
    "# --------------------------------------\n",
    "with open('train.csv', newline='') as csvfile:      # Paste here name and path of the training datacsv on your computer\n",
    "    datareader = csv.reader(csvfile, delimiter=';', quotechar='|')\n",
    "    for row in datareader:\n",
    "        Y_train.append(row[1]\n",
    "        pathtrain.append(row[0])               \n",
    "# --------------------------------------\n",
    "with open('hold_out.csv', newline='') as csvfile:   # Paste here name and path of the scoring csv on your computer\n",
    "    Scoringdatareader = csv.reader(csvfile, delimiter=';', quotechar='|')\n",
    "    for row in datareader:\n",
    "        pathholdout.append(row[0]) \n",
    "                           \n",
    "X_hold_out=np.ones((len(pathholdout), 256, 256, 3))\n",
    "X_train=np.ones((len(pathtrain), 256, 256, 3))\n",
    "for i in range(len(pathholdout)):\n",
    "    img = image.load_img(\"F:\\Hackathon\\All\\{}\".format(pathholdout[i]))  # Replace by local path of images folder\n",
    "    X_hold_out[i]=image.img_to_array(img)[:256,:256,:]\n",
    "    img.close()\n",
    "\n",
    "for i in range(len(pathtrain)):\n",
    "    img2 =image.load_img(\"F:\\Hackathon\\All\\{}\".format(pathtrain[i])) # Replace by local path of images folder\n",
    "    X_train[i]=image.img_to_array(img2)[:256,:256,:]\n",
    "    img2.close()\n",
    "    \n",
    "X_test=X_train[0:set_test_size,:,:,:]\n",
    "Y_test=Y_train[0:set_test_size,:,:,:]\n",
    "\n",
    "X_train/= 255. # Normalise data to [0, 1] range\n",
    "X_test /= 255. # Normalise data to [0, 1] range\n",
    "X_hold_out /= 255. # Normalise data to [0, 1] range\n",
    "#X_train = X_train[:,newaxis,:,:,:] # Reshape in \"convolutionable\" format (add tensor dim for the depth)\n",
    "#X_test = X_test[:,newaxis,:,:,:] # Reshape in \"convolutionable\" format (add tensor dim for the depth)\n",
    "\n",
    "X_train=X_train.reshape(X_train.shape[0],\n",
    "                1,\n",
    "                X_train.shape[1],\n",
    "                X_train.shape[2],\n",
    "                X_train.shape[3])\n",
    "                           \n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(Y_test, num_classes) # One-hot encode the labels\n",
    "\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/billereyagathe/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(6, (5, 5, 5), activation=\"relu\", data_format=\"channels_first\", input_shape=(1, 256, 2..., padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/billereyagathe/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 6, 256, 256, 3)    756       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 128, 128, 3)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 128, 128, 3)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 128, 128, 3)   12016     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 16, 64, 64, 3)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 64, 64, 3)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 196608)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               25165952  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 25,178,982\n",
      "Trainable params: 25,178,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (5, 5, 5), data_format=\"channels_first\", activation=\"relu\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Network params\n",
    "# --------------------------------------\n",
    "# Network params\n",
    "batch_size = 30    # in each iteration, we consider 32 training examples at once\n",
    "num_epochs = 10    # we iterate 20 times over the entire training set\n",
    "kernel_size = 5    # we will use 5x5 kernels throughout\n",
    "pool_size = 2      # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 6   # we will initially have 6 kernels in first conv. layer...\n",
    "conv_depth_2 = 16  # ...switching to 16 after the first pooling layer\n",
    "drop_prob_1 = 0.1  # dropout after pooling with probability 0.1\n",
    "drop_prob_2 = 0.1   # dropout in the FC layer with probability 0.1\n",
    "hidden_size = 128  # the FC layer will have 128neurons\n",
    "weight_penalty = 0.1 # Factor for weights penalty\n",
    "\n",
    "# --------------------------------------\n",
    "# CNN network definition\n",
    "# --------------------------------------\n",
    "# model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "model = Sequential() #(256,256,3,1)\n",
    "# Conv [8] -> Pool (with dropout on the pooling layer)\n",
    "model.add( Conv3D(conv_depth_1, (kernel_size,kernel_size,kernel_size), \n",
    "                  border_mode='same', activation='relu', \n",
    "                  data_format=\"channels_first\",\n",
    "                  input_shape=(1,256, 256, 3)) )#(256,256,3,6)\n",
    "model.add( MaxPooling3D(pool_size=(1,pool_size, pool_size)) )#(128,128,3,6)\n",
    "model.add( Dropout(drop_prob_1) ) \n",
    "\n",
    "# Conv [16] -> Pool (with dropout on the pooling layer)\n",
    "model.add( Conv3D(conv_depth_2, (kernel_size,kernel_size,kernel_size), \n",
    "                  border_mode='same',\n",
    "                  data_format=\"channels_first\",\n",
    "                  activation='relu') )#(128,128,3,16)\n",
    "model.add( MaxPooling3D(pool_size=(1,pool_size, pool_size)) )#(64,64,3,16)\n",
    "model.add( Dropout(drop_prob_1) )\n",
    "\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "model.add( Flatten() )#(64*64*3*16)\n",
    "model.add( Dense(hidden_size, activation='relu', kernel_regularizer=regularizers.l2(weight_penalty)) )#(128)\n",
    "model.add( Dropout(drop_prob_2) )\n",
    "model.add( Dense(num_classes, activation='softmax') )#(2)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guest\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "90/90 [==============================] - 74s 819ms/step - loss: 1.2629 - accuracy: 0.6778\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 73s 810ms/step - loss: 0.4897 - accuracy: 0.8889\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv3d_1_input to have 5 dimensions, but got array with shape (10, 256, 256, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0399fb2a4ba8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# --------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mloss_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The final {} on the test set is: {:.2f}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Evaluate the trained model on the trained set ! test set!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1350\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv3d_1_input to have 5 dimensions, but got array with shape (10, 256, 256, 3)"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Loss function and Optimizer\n",
    "# --------------------------------------\n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "# --------------------------------------\n",
    "# Training\n",
    "# --------------------------------------\n",
    "history = model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1,validation_split=0.2) # ...holding out 20% of the data for validation  ,validation_split=0.2\n",
    "\n",
    "# --------------------------------------\n",
    "# Evaluation\n",
    "# --------------------------------------\n",
    "for loss_name, loss_value in list(zip(model.metrics_names, model.evaluate(X_test, Y_test, verbose=1))):\n",
    "    print('The final {} on the test set is: {:.2f}.'.format(loss_name, loss_value)) # Evaluate the trained model on the trained set ! test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b76b4f8c13c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# --------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model loss by epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Loss functions evolution (let's search for overfitting)\n",
    "# --------------------------------------\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now you can correct this code ( check the regularizations techniques above ) and upload to the platforme the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8ebd43533a26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#to upload on platform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY_score\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scoringdata.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     scoringdatawriter = csv.writer(csvfile, delimiter='; ',\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#to upload on platform \n",
    "Y_hold_out= model.predict(X_score, batch_size=batch_size, verbose=1)\n",
    "\n",
    "with open('Result.csv', 'wb') as csvfile:\n",
    "    scoringdatawriter = csv.writer(csvfile, delimiter='; ',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(len(pathholdout)):\n",
    "        scoringdatawriter.writerow([pathholdout[i], Y_hold_out[i]])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
